\documentclass[12pt]{book}

\usepackage[utf8]{inputenc}
\usepackage[T1, T2A]{fontenc}
\usepackage[russian]{babel}

\usepackage{amsmath,amssymb}

\usepackage[backend=biber, style=numeric]{biblatex}
\addbibresource{thesis.bib}

\usepackage{float}
\usepackage{graphicx}
\graphicspath{ {./pic/} }

\setcounter{secnumdepth}{3}
\newcommand{\cov}{\mathrm{cov}}


\title{Байесовская деконволюция для эксперимента СФЕРА-2}

\author{Игорь Вайман}

\date{\today}

\begin{document}
	\maketitle
	
	\chapter{Описание эксперимента СФЕРА-2}

	Эксперимент СФЕРА-2 основан на сборе и регистрации черенковского света ШАЛ, отражённого от <<экрана>> -- ровной заснеженной поверхности льда озера Байкал. Установка представляет собой сферическое зеркало и мозаику ФЭУ, установленную вблизи фокальной поверхности. Черенковский свет ШАЛ, рассеиваясь на снегу, проходит через диафрагму установки, отражается от зеркала, и попадает на фотокатод. При попадании фотона с длиной волны в области чувствительности фотокатода с него выбиваются $1 - 10$ (уточнить) вторичных электронов, которые проходят систему динодов с разностью потенциалов между каждой парой, создавая в результате избыточный на аноде. Этот заряд стекает с анода через цепь усиления, создавая в результате напряжение на входе АЦП. Это напряжение считывается электроникой, в результате и составляя (вместе с некоторой телеметрией) экспериментальные данные.
	
	Этот набор физических процессов мы описываем в следующих предположениях:
	
	\begin{enumerate}
		\item В системе нет электронных шумов -- единственным источником шума являются фоновые фотоны (от звёздного и зодиакального света, так как эксперимент проводится в ясные безлунные ночи). Фотоны шума попадают в установку аналогично <<сигнальным>> фотонам -- после рассеяния на поверхности. Их поток можно приблизительно оценить по каталогам светимости звёзд и из моделей зодиакального света. (Ссылка на работу Энтиной)
		\item Работу ФЭУ можно эффективно описать одной <<рандомизированной>> испульсной характеристикой (РИХ). Понятие и применение РИХ будет раскрыто далее, в общем виде это случайная функция времени, описывающая отклик системы на один фотон, падающий на фотокатод. Главный источник случайности в установке СФЕРА-2 -- неопределённость числа вторичных фотонов, вылетевших с фотокатода, приводящая к неопределённости амплитуды импульса тока. Стоит отметить, что случайный характер ИХ проявляется именно на границе между режимом счёта фотонов и режимом измерения потока, поскольку поток фотонов уже слишком велик, чтобы разрешать отдельные импульсы, но недостаточно -- чтобы случайные характеристики эффективно усреднялись. Мы также предполагаем, что случайность импульсной характеристики проявлялась независимо между отдельными фотонами и между разными ФЭУ.
		\item Используя экспериментальные данные (данные, записанные АЦП, постоянную компоненту анодного тока и абсолютную калибровку ФЭУ) мы можем восстановить показания анодного тока (ссылка на работу по электронике). Неопределённость, вносимая анодной цепью, усилителем и (главным образом) дискретизацией сигнала на входе АЦП, хорошо известна и учитывается во вторую очередь.
	\end{enumerate}

	\chapter{Байесовская деконволюция}
	
	\section{Общие допущения}
	
	Рассмотрим $N$ последовательных равновеликих временных бинов. Для простоты будем считать единицей времени длительность одного бина. Тогда мы можем задать временные бины интервалами $[i-1, i]$, $i = 1 \ldots N$. Обратим внимание, что при такой нумерации бинов эффект от фотонов, попавших в $i$-тый временной бин проявляется впервые в момент времени $i$. Обозначим число фотонов в каждом бине как $n_i$, $i = 1, \ldots, N$.

	Время прихода отдельного фотона относительно начала бина $t_{inbin} = \{ t \}$ будем описывать случайной величиной, подразумевая, что мы не интересуемся такими детальными характеристиками сигнала. Эта величина может быть, вообще говоря, распределена произвольным образом в интервале $\left[0, 1\right)$, однако мы в простейшем случае будем считать $t_{inbin} \sim U(0, 1)$. Это оправдано для независимых друг от друга фоновых фотонов, и может служить приближением для фотонов ШАЛ в случае, если дисперсия времён прихода фотонов внутри <<пакета>> сильно превышает длительность временного бина. По данным модельных ливней это не всегда так, поэтому влияние неравномерности распределения времён прихода фотонов будет исследовано отдельно.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\columnwidth]{problem-setup-example}
		\caption{Пример данных для задачи байесовской деконволюции. Здесь $N = 50$, количество фотонов в каждом бине выбрано из пуассоновского распределения с $\lambda = \mathbb{E}(n_i) = 15$, они показаны синими столбцами; РИХ -- $A\exp(-t/2)$, обрезанная на $L = 10$, где случайный множитель $A \sim U(0.75, 1)$; оранжевые точки -- выходной сигнал; пунктиром показаны участки, исключаемые из рассмотрения из-за краевых эффектов.}
		\label{pic:problem-setup}
	\end{figure}

	Предположим, что импульсная характеристика системы -- случайная функция $\tilde{h}(t)$ в том смысле, что для входного сигнала, состоящего из конечного числа дельта-функций на единицу времени, каждая из этих дельта функций сворачивается с отдельной независимой реализацией $h(t) \sim \tilde{h}(t)$. Будем также считать, что любая реализация удовлетворяет условию каузальности, то есть $\forall t < 0 \; \; \forall h \sim \tilde{h} \; \; h(t) = 0$, и конечности во времени, то есть $\exists \tilde{L}$ такое, что $\forall t > \tilde{L} \; \; \tilde{h}(t) = 0$.

	Заметим, что эффект от фотонов в $i$-том бине проявляется в отсчётах c $i$ по $i + \left \lfloor{\tilde{L}}\right \rfloor$, где $\left \lfloor{\tilde{L}}\right \rfloor$ -- наибольшее целое число, не превышающее $\tilde{L}$ (округление вниз). Обозначим $L \equiv \left \lfloor{\tilde{L}}\right \rfloor$. Тогда полный сигнал от фотонов гарантированно содержится в отсчётах с $1$ по $N + L$.
	
	Таким образом, фотоны, приходящие на вход в течение времени $\left[0, N\right]$ будут приводить к регистрации отсчётов $s_j$ в моменты времени $j = 1, \ldots, N + L$. Иллюстрация этой постановки задачи приведена на рис. \ref{pic:problem-setup}.
	
	\subsection{Краевые эффекты} \label{sec:edge-effects}
	
	В реальном эксперименте входные фотоны не ограничены интервалом $[0; N]$, но приходят постоянно. Модифицируем постановку задачи так, чтобы устранить краевые эффекты -- плавный рост сигнала в начале и затухание в конце.
	
	Для этого достаточно исключить из всего дальнейшего рассмотрения эти участки сигнала. Так, в реальной ситуации фотоны продолжают приходить после $t=N$, и вносят соответствующий вклад в отсчёты начиная с $N-1$. Фотоны, приходившие до $t=0$, вносят вклад в отсчёты до $L$.
	
	Поэтому для восстановления значений $n_i$, $i = 1, \ldots, N$ мы будем использовать только отсчёты $S_j$ при $j = L+1, \ldots, N$. Этот участок изображён на рис. \ref{pic:problem-setup} сплошной линией, участки по краям, исключаемые из рассмотрения -- пунктиром.
	
	
	\section{Постановка задачи}
	
	Поставим задачу статистической деконволюции следующим образом, используя байесовскую терминологию (поэтому будем также называть эту процедуру байесовской деконволюцией):
	
	\begin{quote}
		Пусть дана рандомизированная импульсная характеристика системы $\tilde{h}(t)$ и значения $s_j, \; j = 1, \ldots, N + L$. Найти апостериорные функции плотности вероятности для значений $n_i$, $i = 1, \ldots, N$.
	\end{quote}
	
	Заметим, что, в отличие от обычной деконволюции, мы не ставим задачу оценить исходный сигнал сам по себе, представляющий собой сумму $\delta$-функций, но только его несколько обобщённую характеристику.

	\section{Решение}

	\subsection{Выходной сигнал как реализация случайного процесса}
	
	Ясно, что в силу случайного характера отклика системы, а также аггрегирования фотонов в бины, значения отсчётов $\{ s_j \}$ являются реализациями некоторых случайных величин. Обозначим сами эти случайные величины как $\{ S_j \}$.

	Запишем $S_j$ как сумму вкладов от фотонов разных бинов
	
	\begin{equation}
		S_j = \sum_{l=0}^{L} C(n_{j-l}, l)
		\label{eq:S-definition-as-random-variable}
	\end{equation}

	Здесь $C(n, l)$ -- случайная величина, описывающая вклад в сигнал на $j$-том временном отсчёте от $n$ фотонов в бине $j - l$, иначе говоря, вклад с \textit{задержкой} $l$ бинов. Из выбранной схемы индексации бинов и условий каузальности и ограниченности во времени РИХ легко видеть, что $l \in \left[0, L\right]$, поскольку вклад от фотонов более ранних бинов равен нулю.
	
	Охарактеризуем распределение $C(n, l)$. Проще всего сделать это через Монте-Карло-сэмплирование распределения этой величины. Получим сначала с произвольной точностью эмпирическую функцию плотности распределения для $C(1, l)$. Для этого сгенерируем значения $t_k \sim t_{inbin};$ и функции $h_k(t) \sim \tilde{h}(t)$ для $k = 1 \ldots N_{sample}$. Выборка для $C(1, l)$ тогда будет состоять из значений $h_k(l + 1 - t_k)$. Выборка для $C(n, l)$ легко получить, проделав описанную процедуру $n$ раз и сложив все $n$ реализаций $N_{sample}$-мерных векторов выборок.

	\subsection{Грубая оценка}
	\label{sec:mean-estimation}
	
	Перед тем, как решать задачу деконволюции в статистическом смысле, сделаем грубую оценку $\vec{n}$, основанную только на соотношениях между математическими ожиданиями случайных величин. Для этого применим операцию вычисления математического ожидания к обеим частям равенства (\ref{eq:S-definition-as-random-variable}).
	
	Фотоны независимы друг от друга в пределах одного бина, из чего следует $ \mathbb{E} \; C(n, l) = n \; \mathbb{E} \, C(1, l)$. Нетрудно заранее вычислить для данной РИХ выборки значений $C(1, l)$ для $l = 0 \ldots L$. Тогда получим, обозначая $c_l \equiv \mathbb{E} \; C(1, l)$,
	
	\begin{equation}
		\bar{S}_j = \mathbb{E} \; S_j = \sum_{l=0}^{L} \mathbb{E} \; C(n_{j-l}, l) = \sum_{l=0}^{L} n_{j-l} \; \mathbb{E} \; C(1, l) = \sum_{l=0}^{L} n_{j-l} c_l
	\end{equation}

	Суммирование можно записать в матричном виде для $j = 1, \ldots, N + L$:
	
	\begin{equation}
		\begin{pmatrix} 
			c_0   &  0   &  0   &\dotsm&  0     \\
			c_1   & c_0  &  0   &\dotsm&  0     \\
			c_2   & c_1  & c_0  &      & \vdots \\
			c_3   & c_2  & c_1  &\ddots&  0     \\
     	    \vdots& c_3  & c_2  &\ddots&  c_0   \\
			c_L   &\vdots& c_3  &\ddots&  c_1   \\
			0     & c_L  &\vdots&\ddots&  c_2   \\
			\vdots&      & c_L  &      &  c_3   \\
			0     &\dotsm&  0   &\ddots& \vdots \\
			0     &\dotsm& 0    &   0  &  c_L   \\
		\end{pmatrix}
		\begin{pmatrix} 
			n_1 \\ n_2 \\ n_3 \\ \vdots \\ n_N
		\end{pmatrix}
		=
		\begin{pmatrix} 
			\bar{S}_1 \\ \bar{S}_2 \\
			\vdots \\
			\bar{S}_N \\ \bar{S}_{N+1} \\
			\vdots \\
			\bar{S}_{N+L}
		\end{pmatrix}
		\label{eq:mean-vector-calculation}
	\end{equation}

	Для перехода к случаю непрерывного потока фотонов достаточно, как указано в разделе \ref{sec:edge-effects}, ограничиться рассмотрением строк $j = L+1, \ldots, N$, то есть убрать первые и последние $L$ уравнений системы.

	Эта возможно несовместная система линейных уравнений, допускает решение в смысле наименьших квадратов с помощью псевдообратной матрицы Мура-Пенроуза \cite{Penrose1956}. Псевдообратная матрица $C^+$ для $C$ определяется следующими условиями: (1) $C C^+ C = C$, (2) $C^+ C C^+ = C^+$, (3) $C C^+$ и $C^+ C$ -- эрмитовы матрицы. Псевдообратная матрица всегда существует, и для системы $C\vec{n} = \vec{S}$ вектор $C^+ \vec{S}$ даёт искомое МНК-решение системы. Приближённый численный расчёт такой матрицы можно провести, например, с помощью функции \verb|pinv| модуля \verb|numpy.linalg| в Python \cite{Harris2020}.

	\begin{figure}[H]
		\centering
		\includegraphics[width=\columnwidth]{mean-estimation}
		\caption{Оценка $\vec{n}$ в предположении, что выходной сигнал $\vec{s}$ равен своему математическому ожиданию. Пунктиром показана область, где оценка искажена эффектом ограниченности выборки во времени.}
		\label{pic:mean-estimation}
	\end{figure}
	
	Однако для решения системы необходимо знать $\mathbb{E} \, S_j$, в то время как в эксперименте мы имеем всего лишь единственную реализацию этой случайной величины $s_j$. Для грубой оценки остаётся положить $\mathbb{E} \; S_j \approxeq s_j$. Результат описанной процедуры приведён на рис. \ref{pic:mean-estimation} фиолетовым, пунктиром отмечена область, в которой оценка искажена краевым эффектом, её необходимо отбросить.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=\columnwidth]{mean-estimation-assessment}
		\caption{Распределения истинных и грубо восстановленных значений $\vec{n}$ для 1000 значений. Истинные значения выбраны из пуассоновского распределения с $\lambda = 15$, аналогично рис. \ref{pic:problem-setup} и \ref{pic:mean-estimation}.}
		\label{pic:mean-estimation-assessment}
	\end{figure}
	
	Строгое исследование свойств такой <<one-shot>> оценки $\vec{n}$ находится за рамками данной работы. Однако для простой численной проверки можно провести описанную процедуру для большего числа входных бинов и сравнить распределения истинных и оцененных значений $\vec{n}$. На рис. \ref{pic:mean-estimation-assessment} приведено такое сравнение для 1000 бинов. Видно, что распределения практически совпадают, а значит отсутствует по крайней мере систематическая ошибка. В дальнейшем эта оценка будет играть роль первого приближения, или стартовой точки, на основе которой уже полными статистическим методом можно найти полное решение.
	
	\subsection{Полное решение задачи байесовской деконволюции}
	
	Теперь перейдём к решению полноценной статистической задачи, используя метод, описанный в предыдущем разделе, как первое приближение.
	
	Запишем сначала теорему Байеса в общем виде, учитывая, что наблюдаемыми значениями является сигнал $\vec{s}$, а неизвестными параметрами, которые задают распределение наблюдаемых -- $\vec{n}$:
	
	\begin{equation}
		P(\vec{n} | \vec{s}) = \frac{P(\vec{s} | \vec{n}) \, P(\vec{n})}{P(\vec{s})}
	\end{equation}

	Поясним вероятности, входящие в выражение: 
	
	\begin{enumerate}
		\item $P(\vec{n} | \vec{s})$ -- искомое \textit{апостериорное} распределение, описывающее (в байесовском определении вероятности) наши знания о $\vec{n}$ после проведения измерений
		\item $P(\vec{s} | \vec{n}) \equiv \mathcal{L}(\vec{s}, \vec{n})$ -- функция правдоподобия, описывающая, насколько вероятна регистрация определённых значений $\vec{s}$ при заданных параметрах $\vec{n}$
		\item $P(\vec{n}) \equiv \pi(\vec{n})$ -- \textit{априорное} распределение $\vec{n}$, не требующее знаний о конкретном выходном сигнале
		\item $P(\vec{s})$ -- полная вероятность регистрации данного сигнала при всех возможных значениях $\vec{n}$. Она также называемая маргинальной вероятностью или нормировочным множителем, по определению $P(\vec{s}) = \int_{\infty} P(\vec{s} | \vec{n}) \, P(\vec{n}) d\vec{n}$. Эту величину можно использовать для сравнения моделей, например, если бы мы имели в распоряжении альтернативную модель генерации значений $\vec{s}$ и хотели бы понять, какая из двух лучше описывает данные. Однако для поставленной задачи нет нужды ни вычислять, ни даже учитывать этот множитель.
	\end{enumerate}

	Учитывая введённые обозначения, запишем

	\begin{equation}
		\label{eq:bayes-theorem-adapted}
		P(\vec{n} | \vec{s}) \propto \mathcal{L}(\vec{s}, \vec{n}) \, \pi(\vec{n})
	\end{equation}

	\subsubsection{Выбор априорного распределения}
	
	В качестве априорного распределения будем использовать неограниченное равномерное, или \textit{неинформативное} распределение. Методы байесовской статистики работают даже в ситуации, когда у нас нет вообще никакой информации о распределении $\vec{n}$ до начала измерений. Формально для этого нужно положить $\pi(\vec{n}) = Const \; \forall \vec{n}$. Такое распределение нельзя использовать напрямую, поскольку его невозможно отнормировать на $1$. Однако тогда в выражении \ref{eq:bayes-theorem-adapted} можно просто исключить $\pi(\vec{n})$ из правой части.
	
	\textbf{TBD} Пуассоновское априрное распределение. Базовое предположение задачи -- фотонный шум на входе нескоррелирован, а значит, приводит к пуассоновскому распределению $\vec{n}$. Для реального сигнала параметр $\lambda$ можно оценить грубым методом, описанным в разделе \ref{sec:mean-estimation} на достаточно большом числе отсчётов в области отсутствия сигнала. Пока же мы можем положить, что нам точно известен параметр $\lambda$ для фотонов на входе. Заметим, что это априорное распределение справедливо также и в области, где мы стремимся найти сигнал. В этом случае
	
	\subsubsection{Функция правдоподобия}
	
	Функция правдоподобия $\mathcal{L}(\vec{s}, \vec{n})$ определяется как вероятность того, что данный сигнал $\vec{s}$ получился в результате преобразования системой входного сигнала $\vec{n}$.

	Опишем сначала Монте-Карло метод оценки правдоподобия, и затем введём упрощения, которые позволят эффективнее вычислять эту функцию, а также обоснуем корректность этих упрощений.

	\subsubsection{Полное вычисление функции правдоподобия методом Монте-Карло}
	
	\label{sec:naive-monte-carlo-likelihood}

	Идейно наиболее простой метод состоит в прямой оценке $\mathcal{L}(\vec{s}, \vec{n})$ методом Монте-Карло. При фиксированных $\vec{n}$ необходимо смоделировать выборку из большого числа реализаций случайной величины $\vec{S}$, а затем оценить плотность вероятности в точке $\vec{s}$ по этой выборке.
	
	Существует несколько методов для такой оценки, самый простой из которых -- многомерная гистограмма. Для этого пространство реализаций $\vec{S}$ делится на ячейки, подсчитывается число элементов выборки, попавших в каждую ячейку, делится на общее число элементов выборки и на объём ячейки. Нетрудно видеть, что полученное число как раз и даёт оценку плотности вероятности в произвольной точке -- и, с точки зрения нашей задачи, искомую оценку функции правдоподобия.
	
	Эффективная реализация алгоритма оценки $n$-мерной функции плотности вероятности дана в приложении \textbf{! TBD !}, алгоритм аналогичен пакету \verb|MEPDF| в языке \verb|R| \cite{Wiegand2019}.
	
	Однако оказывается, что для поставленной задачи метод прямого вычисления функции правдоподобия плохо годится из-за <<проклятия размерности>>. Размерность пространства, в котором нужно оценить эмпирическую функцию плотности вероятности, равна ширина окна, в котором рассматривается входной сигнал. Соответственно, общее число $N$-мерных бинов составляет $g^{N}$, где $g$ -- мощность бинирования каждого отсчёта. В этой ситуации для надёжной оценки придётся генерировать выборку сравнимого объёма.
	
	Поэтому вместо прямого использования описанного метода аппроксимируем распределение $\vec{S}$ более доступной к вычислению формой.

	\subsubsection{Аппроксимация $\mathcal{L}(\vec{S})$ многомерным нормальным распределением}
	
	\label{sec:likelihood-as-multivar-normal}
	
	\paragraph{Частные распределения}

	Из общих соображения ясно, что распределение $S_j \forall j$ будет более или менее близко к нормальному просто в силу того, что каждая из этих величин является суммой независимых вкладов от фотонов в предыдущих бинах. Также из общих соображений можно сказать, что \textit{чем меньше среднее число фотонов в бине, тем хуже будет аппроксимация нормальным распределением}. На рис. \ref{pic:s-j-norm-assess} приведены несколько распределений <<лучшего>>, <<медианного>> и <<худшего>> распределений $S_j$ для нескольких значений среднего число фотонов в бине $\bar{n} \equiv \mathbb{E} \, n_i$. Из предварительного анализа и независимых соображений известно, что менее $5$ фотонов на бин -- весьма нечастая ситуация в экспериментальных данных -- но даже в этом случае видно, что самое существенное отклонение плотности распределения от гауссианы не превышет 7\%. Таким образом, \textit{частное распределение} каждой компоненты вектора $\vec{S}$ можно приблизить нормальным распределением с эффективной погрешностью в несколько процентов для практически значимых случаев.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=\columnwidth]{S-j-normality-assessment.pdf}
		\caption{Оценка нормальности частных распределений компонент $\vec{S}$ для разных интенсивностей входного потока: от экстремально низких $1$ и $2$ до средней ожидаемой $10$. <<Лучший>>, <<медианный>> и <<худший>> бины определены эвристически по квадрату разницы выборочного среднего и медианы (чем больше эта величина, тем менее симметрично распределение). На каждом графике построена плотность нормального распределения с соответствующими $\mu$ и $\sigma$, а также приведено среднеквадратичное отклонение гистограммы от гауссианы в процентах относительно максимального значения.}
		\label{pic:s-j-norm-assess}
	\end{figure}

	\paragraph{Полное $(N-L)$-мерное распределение}
	Описанная процедура для полного многомерного распределения представляет собой непростую задачу, поэтому ограничимся здесь визуальным исследованием двумерных распределений пар значений в отсчётах, разделённых не более чем $L$ бинами (из постановки задачи ясно, что на больших расстояниях $S_j$ являются независимыми). На рис. \ref{pic:s-j-pairwise-norm-assess} представлены такие распределения. Видно, что двумерные распределения представляют собой овалы правильной симметричной формы. Таким образом, можно положить, что \textit{распределение вектора $\vec{S}$ можно приблизить многомерным нормальным распределением}. Можно также сказать, что мы можем описывать $\vec{S}$ как выборку из \textit{гауссова процесса}.

	\begin{figure}[H]
		\centering
		\includegraphics[width=1.2\columnwidth]{S-j-pairwise-normality-assessment.pdf}
		\caption{Оценка нормальности совместных двумерных распределений для пар компонент $\vec{S}$. График построен с помощью библиотеки corner \cite{ForemanMackey2016}.}
		\label{pic:s-j-pairwise-norm-assess}
	\end{figure}

	\subsubsection{Аппроксимация функции правдоподобия многомерным нормальным распределением}
	
	Как описано в разделе \ref{sec:likelihood-as-multivar-normal}, распределение $\vec{S}$ действительно можно приближённо описать многомерным нормальным. Пользуясь этим, построим аппроксимацию функции правдоподобия $\mathcal{L}(\vec{n}) \equiv P(\vec{S} | \vec{n})$, гораздо более устойчивую и вычислительно эффективную, чем наивный метод Монте-Карло, описанный в разделе \ref{sec:naive-monte-carlo-likelihood}.

	Многомерное нормальное распределение в общем виде задаётся вектором математических ожиданий $\vec{\mu}$ и матрицой ковариаций $\Sigma$. Функция плотности вероятности $(N+L)$-мерного случайного вектора $\vec{S}$ тогда задаётся выражением
	
	\begin{equation}
		p(\vec{S}) = \left( (2 \pi)^{N+L} \, \det \Sigma \right)^{-1/2} \exp \left( - \frac{1}{2} (\vec{S} - \vec{\mu})^T \Sigma^{-1} (\vec{S} - \vec{\mu}) \right)
	\end{equation}

	Вектор $\vec{\mu} \equiv \mathbb{E} \, \vec{S}$ при данных $\vec{n}$ вычисляется в соответствии с выражением (\ref{eq:mean-vector-calculation}). Вычислим произвольный элемент матрицы $\Sigma_{ij} \equiv \cov\left( S_i, S_j \right)$. В силу симметричности матрицы ковариаций можно положить для определённости $i \le j$. Запишем выражение (\ref{eq:S-definition-as-random-variable}) для двух интересующих нас элементов $\vec{S}$:
	
	\begin{align}
		S_i &= \sum_{l=0}^{L} C(n_{i-l}, l)\\
		S_j &= \sum_{k=0}^{L} C(n_{j-k}, k)
	\end{align}

	Источник ненулевой ковариации двух сумм -- члены, описывающие вклады фотонов из одного бина, но на разных задержках, все прочие вклады независимы, а значит имеют нулевую корреляцию. Условие, описывающим такие попарно-скоррелированные члены, получается из равенства индексов $n$ в суммах: $i-l = j-k$. Вводя $\Delta \equiv j - i$, отсюда получаем $k = l + \Delta$. Отсюда сразу следует интуитивный вывод о том, что при $\Delta > L$ ковариация будет заведомо нулевой в силу конечности РИХ во времени.

	Используем следующее свойство ковариации: если $x$, $y$, $\epsilon$, $\eta$ -- случайные величины, из которых только $x$ и $y$ являются зависимыми, то $\cov(x + \epsilon, y + \eta) = \cov(x, y)$. Иначе говоря, заведомо независимые члены при вычислении ковариации можно просто опустить. Проделаем это в суммах выше, получив таким образом <<скореллированные части>> $\hat{S}_i$ и $\hat{S}_j$ такие, что $\cov ( S_i, S_j  ) = \cov ( \hat{S}_i, \hat{S}_j )$:
	
	\begin{align}
		\hat{S}_i &= \sum_{l=0}^{L-\Delta} C(n_{i-l}, l)\\
		\hat{S}_j &= \sum_{k=\Delta}^{L} C(n_{j-k}, k) = \left[k=l+\Delta\right] = \sum_{l=0}^{L-\Delta} C(n_{i-l}, l+\Delta)
	\end{align}

	Наконец, используем ещё одно свойство ковариации: если среди случайных величин $x_1$, $x_2$, $y_1$, $y_2$ независимы все пары, кроме $x_1$ и $y_1$, $x_2$ и $y_2$, то $\cov(x_1 + x_2, \, y_1 + y_2) = \cov(x_1, y_1) + \cov(x_2, y_2)$. Индуктивно обобщая на случай сумм с произвольным числом членов, и принимая во внимание, что фотоны в разных бинах независимы, получаем
	
	\begin{equation}
		\cov(S_i, S_j) = \cov(\hat{S}_i, \hat{S}_j) = \sum_{l=0}^{L - \Delta} \cov(C(n_{i-l}, l), C(n_{i-l}, l + \Delta))
	\end{equation}

	Наконец, принимая во внимание, что сама по себе величина $C(n, l)$ есть сумма $n$ независимых одинаково распределённых случайных величин, а между членами сумм $C(n, l)$ и $C(n, l + \Delta)$ есть только попарные корреляции в отношении 1 к 1, можно записать окончательную формулу для вычисления элемента матрицы ковариации:
	
	\begin{equation}
		\cov(S_i, S_{i + \Delta}) = \sum_{l=0}^{L - \Delta} n_{i-l} \; \cov\left(C(1, l), C(1, l + \Delta)\right)
	\end{equation}

	Из формулы видно, что автокорреляция сигнала описана полностью в терминах автокорреляции РИХ и чисел фотонов в соответствующих бинах, служащих весами для вклада разных участков РИХ.
	
	Для удобства вычислений можно записать это равенство в матричном виде для значений $\Delta \in \left[0; L\right]$. Для этого введём обозначение $\xi(l, \Delta) \equiv \cov\left(C(1, l), C(1, l + \Delta)\right)$ и с помощью него запишем:
	
	\begin{equation}
		\begin{pmatrix} 
			\xi(L, 0) & \xi(L-1, 0) & \xi(L-2, 0) & \dotsm & \xi(0, 0) \\
			     0    & \xi(L-1, 1) & \xi(L-2, 1) & \dotsm & \xi(0, 1) \\
				 0    &      0      & \xi(L-2, 2) & \dotsm & \xi(0, 2) \\
			   \vdots &   \vdots    &    \vdots   & \ddots &   \vdots  \\
			     0    &      0      &      0      & \dotsm & \xi(0, L)
		\end{pmatrix}
		\begin{pmatrix} 
			n_{i-L} \\ n_{i-(L-1)} \\ n_{i-(L-2)} \\ \vdots \\ n_{i}
		\end{pmatrix}
		=
		\begin{pmatrix} 
			\Sigma_{i, i} \\
			\Sigma_{i, i+1} \\ 
			\Sigma_{i, i+2} \\ 
			\vdots \\ 
			\Sigma_{i, i+L}
		\end{pmatrix}
		\label{eq:Xi-matrix-for-Sigma-calculation}
	\end{equation}

	Это достаточно громоздкое и неинтуитивное выражение позволяет, однако, единожды вычислить матрицу $\Xi$ и эффективно рассчитывать матрицу ковариаций $\Sigma$ при каждом заданном $\vec{n}$.
	
	После исключения областей влияния краевых эффектов -- первых и последних $L$ элементов $\vec{S}$ -- нас будут интересовать только внутренняя часть матрицы $\Sigma$, то есть индексы $i, j \in [L + 1; N]$. Для вычисления 

	\printbibliography
	
\end{document}
